{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "from spacy import attrs\n",
    "import numpy as np\n",
    "\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067102\n",
      "1004314\n"
     ]
    }
   ],
   "source": [
    "pdfList = []\n",
    "for i in range(1,26):\n",
    "    pdfList.append(str(i)+\".PDF\")\n",
    "\n",
    "text = []\n",
    "for pdf in pdfList:\n",
    "    with open(pdf, 'rb') as pdfFileObj:\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        for page in range(1,pdfReader.getNumPages()):\n",
    "            pageObj = pdfReader.getPage(page)\n",
    "            text.append(pageObj.extractText())\n",
    "\n",
    "docTrain1 = ' '.join(text) #combine all pages into a String doc\n",
    "print (len(docTrain1))\n",
    "\n",
    "text = [] \n",
    "with open('HungerGames.pdf', 'rb') as pdfFileObj:\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    for page in range(1,pdfReader.getNumPages()):\n",
    "        pageObj = pdfReader.getPage(page)\n",
    "        text.append(pageObj.extractText())\n",
    "\n",
    "with open('HarryPotter.pdf', 'rb') as pdfFileObj:\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    for page in range(1,pdfReader.getNumPages()):\n",
    "        pageObj = pdfReader.getPage(page)\n",
    "        text.append(pageObj.extractText())\n",
    "        \n",
    "docTrain0 = ' '.join(text) #combine all pages into a String doc\n",
    "print (len(docTrain0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8946\n",
      "17310\n"
     ]
    }
   ],
   "source": [
    "parsedData = parser(docTrain1)\n",
    "\n",
    "sents1 = []\n",
    "for span in parsedData.sents:\n",
    "    sent = ''.join(parsedData[i].string for i in range(span.start, span.end)).strip()\n",
    "    sents1.append(sent)\n",
    "print (len(sents1))\n",
    "\n",
    "parsedData = parser(docTrain0)\n",
    "\n",
    "sents0 = []\n",
    "for span in parsedData.sents:\n",
    "    sent = ''.join(parsedData[i].string for i in range(span.start, span.end)).strip()\n",
    "    sents0.append(sent)\n",
    "print (len(sents0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Every step in a pipeline needs to be a \"transformer\". \n",
    "# Define a custom transformer to clean text using spaCy\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert text to cleaned text\n",
    "    \"\"\"\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# A custom function to clean the text before sending it into the vectorizer, called by Transformer\n",
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    # replace twitter @mentions\n",
    "    mentionFinder = re.compile(r\"@[a-z0-9_]{1,15}\", re.IGNORECASE)\n",
    "    text = mentionFinder.sub(\"@MENTION\", text)\n",
    "    \n",
    "    # replace HTML symbols\n",
    "    text = text.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# A custom function to tokenize the text using spaCy\n",
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    \n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "    \n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training data\n",
    "train = sents1+sents0\n",
    "\n",
    "labelsTrain = []\n",
    "for i in range(0,len(train)):\n",
    "    if (i < len(sents1)):\n",
    "        labelsTrain.append(1)\n",
    "    else:\n",
    "        labelsTrain.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# define test data\n",
    "test = [\"Plaintiffs failed to establish\",\n",
    "        \"challenged statutes violate equal protection\",\n",
    "        \"I just want to eat a hamburger\", \n",
    "        \"this is just another sentence\", \n",
    "        \"the quick brown fox jumped\",\n",
    "        \"courts and statutes\", \n",
    "        \"over the lazy dog\",\n",
    "        \"what time is the party\",\n",
    "        \"what are my legal rights\",\n",
    "        \"due process in civil court\",\n",
    "        \"what time is it\",\n",
    "        \"let's run to the park and have fun\",\n",
    "        \"let's add come complexity to this sentence\",\n",
    "        \"What would be a good test\",\n",
    "        \"who in the world knows all about\",\n",
    "        \"I will be getting home late today\",\n",
    "        \"the plaintiff alleges that the defendant\",\n",
    "        \"Three more sentences to go here\",\n",
    "        \"let's hurry up so we can go home\",\n",
    "        \"she went to court today and\"]\n",
    "labelsTest = [1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "\n",
    "print (len(test))\n",
    "print (len(labelsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the vectorizer and classifer to use\n",
    "# note that I changed the tokenizer in CountVectorizer to use a custom function using spaCy's tokenizer\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,4))\n",
    "lsa = TruncatedSVD(100, algorithm = 'randomized')\n",
    "clf = LinearSVC()\n",
    "# the pipeline to clean, tokenize, vectorize, and classify\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer),('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cleanText', <__main__.CleanTextTransformer object at 0x1808d66a0>), ('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       " ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "pipe.fit(train, labelsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaintiffs failed to establish : 1\n",
      "challenged statutes violate equal protection : 1\n",
      "I just want to eat a hamburger : 0\n",
      "this is just another sentence : 0\n",
      "the quick brown fox jumped : 0\n",
      "courts and statutes : 1\n",
      "over the lazy dog : 0\n",
      "what time is the party : 0\n",
      "what are my legal rights : 0\n",
      "due process in civil court : 1\n",
      "what time is it : 0\n",
      "let's run to the park and have fun : 0\n",
      "let's add come complexity to this sentence : 0\n",
      "What would be a good test : 0\n",
      "who in the world knows all about : 0\n",
      "I will be getting home late today : 0\n",
      "the plaintiff alleges that the defendant : 1\n",
      "Three more sentences to go here : 0\n",
      "let's hurry up so we can go home : 0\n",
      "she went to court today and : 1\n",
      "\n",
      " Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "preds = pipe.predict(test)\n",
    "\n",
    "for (sample, pred) in zip(test, preds):\n",
    "    print(sample, \":\", pred)\n",
    "\n",
    "print(\"\\n\",\"Accuracy:\", accuracy_score(labelsTest, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GET TWITTER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import cnfg\n",
    "from os.path import expanduser\n",
    "\n",
    "home = expanduser(\"~\")\n",
    "config = cnfg.load(home + \"/.twitter_config\")\n",
    "\n",
    "auth = tweepy.OAuthHandler(config[\"consumer_key\"],\n",
    "                           config[\"consumer_secret\"])\n",
    "auth.set_access_token(config[\"access_token\"],\n",
    "                      config[\"access_token_secret\"])\n",
    "\n",
    "api=tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def structure_results(results, handle):\n",
    "    id_list = [tweet.id for tweet in results]\n",
    "    data = pd.DataFrame(id_list,columns=['id'])\n",
    "    \n",
    "    data[\"Handle\"] = handle\n",
    "    data[\"Text\"] = [tweet.text for tweet in results]\n",
    "    data[\"Datetime\"] = [tweet.created_at for tweet in results]\n",
    "    data[\"Location\"] = [tweet.place for tweet in results]\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Replace https...with empty string\n",
    "def httpRemove(text):\n",
    "    if re.search('https?:\\/\\/.*[\\r\\n]*', text):\n",
    "        return re.sub('https?:\\/\\/.*[\\r\\n]*', '', text).strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Replace @.... with empty string\n",
    "def atRemove(text):\n",
    "    if re.search('@([\\w.-]+)', text):\n",
    "        return re.sub('@([\\w.-]+)', '', text).strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Replace #.... with empty string\n",
    "def hashRemove(text):\n",
    "    if re.search('#([\\w.-]+)', text):\n",
    "        return re.sub('#([\\w.-]+)', '', text).strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def toPandas(userText, preds):\n",
    "    id_list=[i for i in range(0,len(preds))]\n",
    "    data=pd.DataFrame(id_list,columns=['tweet_id'])\n",
    "    \n",
    "    data[\"text\"]= [tweet for tweet in userText]\n",
    "    data[\"Prediction\"] = [prediction for prediction in preds]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "handles = ['NinaTotenberg', 'justinbieber', 'LeoDiCaprio', 'espn','EricHolder','Snowden','jimmykimmel','realDonaldTrump']\n",
    "#handles = ['NinaTotenberg']\n",
    "\n",
    "frames = []\n",
    "for handle in handles:\n",
    "    tweets = tweepy.Cursor(api.user_timeline,id=handle).items(1000)\n",
    "    results = []\n",
    "    print (handle)\n",
    "    for tweet in tweets:\n",
    "        results.append(tweet)\n",
    "    \n",
    "    data = structure_results(results, handle)\n",
    "    frames.append(data)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldata = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata[\"text_no_https\"] = alldata.Text.apply(httpRemove)\n",
    "\n",
    "alldata[\"text_no_https_at\"] = alldata.text_no_https.apply(atRemove)\n",
    "\n",
    "alldata[\"text_no_https_at_hash\"] = alldata.text_no_https_at.apply(hashRemove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userText = []\n",
    "for text in alldata.text_no_https_at_hash:\n",
    "    userText.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "preds = pipe.predict(userText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata['Prediction'] = [p for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NinaTotenberg 0.459357277883\n",
      "justinbieber 0.173\n",
      "LeoDiCaprio 0.178410794603\n",
      "espn 0.258\n",
      "EricHolder 0.337209302326\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 120)\n",
    "\n",
    "alldata['Rating'] = 0\n",
    "for handle in alldata.Handle.unique():\n",
    "    rating = alldata[alldata['Handle'] == handle].Prediction.sum()/alldata[alldata['Handle'] == handle].Prediction.count()\n",
    "    print (handle, rating)\n",
    "    alldata.loc[alldata['Handle'] == handle,'Rating'] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Location</th>\n",
       "      <th>text_no_https</th>\n",
       "      <th>text_no_https_at</th>\n",
       "      <th>text_no_https_at_hash</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>738369861181546496</td>\n",
       "      <td>NinaTotenberg</td>\n",
       "      <td>SG Donald Verrilli stepping down after 5 yrs of historic #SCOTUS arguments, from Obamacare to same-sex marriage. htt...</td>\n",
       "      <td>2016-06-02 14:01:07</td>\n",
       "      <td>None</td>\n",
       "      <td>SG Donald Verrilli stepping down after 5 yrs of historic #SCOTUS arguments, from Obamacare to same-sex marriage.</td>\n",
       "      <td>SG Donald Verrilli stepping down after 5 yrs of historic #SCOTUS arguments, from Obamacare to same-sex marriage.</td>\n",
       "      <td>SG Donald Verrilli stepping down after 5 yrs of historic  arguments, from Obamacare to same-sex marriage.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737749855993466880</td>\n",
       "      <td>NinaTotenberg</td>\n",
       "      <td>Amid prickly dissents from right and left  #SCOTUS weighs In on 2 death penalty cases https://t.co/4u11eqr8yI</td>\n",
       "      <td>2016-05-31 20:57:27</td>\n",
       "      <td>None</td>\n",
       "      <td>Amid prickly dissents from right and left  #SCOTUS weighs In on 2 death penalty cases</td>\n",
       "      <td>Amid prickly dissents from right and left  #SCOTUS weighs In on 2 death penalty cases</td>\n",
       "      <td>Amid prickly dissents from right and left   weighs In on 2 death penalty cases</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>737705151679598592</td>\n",
       "      <td>NinaTotenberg</td>\n",
       "      <td>SCOTUS declines to hear #Trump Resorts bankruptcy case that stripped workers of health insurance &amp;amp; pension benef...</td>\n",
       "      <td>2016-05-31 17:59:48</td>\n",
       "      <td>None</td>\n",
       "      <td>SCOTUS declines to hear #Trump Resorts bankruptcy case that stripped workers of health insurance &amp;amp; pension benef...</td>\n",
       "      <td>SCOTUS declines to hear #Trump Resorts bankruptcy case that stripped workers of health insurance &amp;amp; pension benef...</td>\n",
       "      <td>SCOTUS declines to hear  Resorts bankruptcy case that stripped workers of health insurance &amp;amp; pension benefits.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735550431049486336</td>\n",
       "      <td>NinaTotenberg</td>\n",
       "      <td>Are Justices #Alito and #Thomas sore losers? Interesting perspective: https://t.co/ibt0DLwUhw</td>\n",
       "      <td>2016-05-25 19:17:43</td>\n",
       "      <td>None</td>\n",
       "      <td>Are Justices #Alito and #Thomas sore losers? Interesting perspective:</td>\n",
       "      <td>Are Justices #Alito and #Thomas sore losers? Interesting perspective:</td>\n",
       "      <td>Are Justices  and  sore losers? Interesting perspective:</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>735158217752346624</td>\n",
       "      <td>NinaTotenberg</td>\n",
       "      <td>Your legal affairs queen isn’t always serious. She’s also a dancing queen. https://t.co/1nHpqFdzPh @washingtonpost h...</td>\n",
       "      <td>2016-05-24 17:19:12</td>\n",
       "      <td>None</td>\n",
       "      <td>Your legal affairs queen isn’t always serious. She’s also a dancing queen.</td>\n",
       "      <td>Your legal affairs queen isn’t always serious. She’s also a dancing queen.</td>\n",
       "      <td>Your legal affairs queen isn’t always serious. She’s also a dancing queen.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id         Handle  \\\n",
       "0  738369861181546496  NinaTotenberg   \n",
       "1  737749855993466880  NinaTotenberg   \n",
       "2  737705151679598592  NinaTotenberg   \n",
       "3  735550431049486336  NinaTotenberg   \n",
       "4  735158217752346624  NinaTotenberg   \n",
       "\n",
       "                                                                                                                      Text  \\\n",
       "0  SG Donald Verrilli stepping down after 5 yrs of historic #SCOTUS arguments, from Obamacare to same-sex marriage. htt...   \n",
       "1            Amid prickly dissents from right and left  #SCOTUS weighs In on 2 death penalty cases https://t.co/4u11eqr8yI   \n",
       "2  SCOTUS declines to hear #Trump Resorts bankruptcy case that stripped workers of health insurance &amp; pension benef...   \n",
       "3                            Are Justices #Alito and #Thomas sore losers? Interesting perspective: https://t.co/ibt0DLwUhw   \n",
       "4  Your legal affairs queen isn’t always serious. She’s also a dancing queen. https://t.co/1nHpqFdzPh @washingtonpost h...   \n",
       "\n",
       "             Datetime Location  \\\n",
       "0 2016-06-02 14:01:07     None   \n",
       "1 2016-05-31 20:57:27     None   \n",
       "2 2016-05-31 17:59:48     None   \n",
       "3 2016-05-25 19:17:43     None   \n",
       "4 2016-05-24 17:19:12     None   \n",
       "\n",
       "                                                                                                             text_no_https  \\\n",
       "0         SG Donald Verrilli stepping down after 5 yrs of historic #SCOTUS arguments, from Obamacare to same-sex marriage.   \n",
       "1                                    Amid prickly dissents from right and left  #SCOTUS weighs In on 2 death penalty cases   \n",
       "2  SCOTUS declines to hear #Trump Resorts bankruptcy case that stripped workers of health insurance &amp; pension benef...   \n",
       "3                                                    Are Justices #Alito and #Thomas sore losers? Interesting perspective:   \n",
       "4                                               Your legal affairs queen isn’t always serious. She’s also a dancing queen.   \n",
       "\n",
       "                                                                                                          text_no_https_at  \\\n",
       "0         SG Donald Verrilli stepping down after 5 yrs of historic #SCOTUS arguments, from Obamacare to same-sex marriage.   \n",
       "1                                    Amid prickly dissents from right and left  #SCOTUS weighs In on 2 death penalty cases   \n",
       "2  SCOTUS declines to hear #Trump Resorts bankruptcy case that stripped workers of health insurance &amp; pension benef...   \n",
       "3                                                    Are Justices #Alito and #Thomas sore losers? Interesting perspective:   \n",
       "4                                               Your legal affairs queen isn’t always serious. She’s also a dancing queen.   \n",
       "\n",
       "                                                                                                text_no_https_at_hash  \\\n",
       "0           SG Donald Verrilli stepping down after 5 yrs of historic  arguments, from Obamacare to same-sex marriage.   \n",
       "1                                      Amid prickly dissents from right and left   weighs In on 2 death penalty cases   \n",
       "2  SCOTUS declines to hear  Resorts bankruptcy case that stripped workers of health insurance &amp; pension benefits.   \n",
       "3                                                            Are Justices  and  sore losers? Interesting perspective:   \n",
       "4                                          Your legal affairs queen isn’t always serious. She’s also a dancing queen.   \n",
       "\n",
       "   Prediction    Rating  \n",
       "0           1  0.459357  \n",
       "1           1  0.459357  \n",
       "2           1  0.459357  \n",
       "3           0  0.459357  \n",
       "4           0  0.459357  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata.to_pickle('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NinaTotenberg 0.459357277883\n",
      "justinbieber 0.173\n",
      "LeoDiCaprio 0.178410794603\n",
      "espn 0.258\n",
      "EricHolder 0.337209302326\n"
     ]
    }
   ],
   "source": [
    "idList = []\n",
    "r = []\n",
    "for handle in alldata.Handle.unique():\n",
    "    print (handle, alldata[alldata['Handle'] == handle].Rating[0])\n",
    "    \n",
    "    idList.append(handle)\n",
    "    r.append(alldata[alldata['Handle'] == handle].Rating[0])\n",
    "\n",
    "smallDataframe = pd.DataFrame(idList,columns=['Handle'])\n",
    "smallDataframe[\"Rating\"] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Handle</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NinaTotenberg</td>\n",
       "      <td>0.459357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EricHolder</td>\n",
       "      <td>0.337209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>espn</td>\n",
       "      <td>0.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LeoDiCaprio</td>\n",
       "      <td>0.178411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>justinbieber</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Handle    Rating\n",
       "0  NinaTotenberg  0.459357\n",
       "4     EricHolder  0.337209\n",
       "3           espn  0.258000\n",
       "2    LeoDiCaprio  0.178411\n",
       "1   justinbieber  0.173000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallDataframe = smallDataframe.sort_values('Rating', ascending = False)\n",
    "smallDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smallDataframe.to_pickle('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1876b8470>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAERCAYAAACdPxtnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+htlTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x188ed7630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(smallDataframe['Handle'],smallDataframe['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
